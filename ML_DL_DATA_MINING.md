# Machine Learning, Deep Learning & Data Mining dans EduPath

Ce document explique en d√©tail o√π et comment les technologies de Machine Learning (ML), Deep Learning (DL) et Data Mining sont utilis√©es dans le projet EduPath.

---

## üìä Vue d'ensemble

EduPath est une plateforme d'apprentissage adaptatif qui utilise plusieurs techniques d'IA pour :
- **Pr√©dire** les risques d'√©chec des √©tudiants
- **Profiler** les √©tudiants selon leurs comportements d'apprentissage
- **Recommander** des ressources p√©dagogiques personnalis√©es
- **Analyser** les donn√©es d'apprentissage pour optimiser les parcours

---

## üéØ Architecture ML/DL

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   LMS Connector ‚îÇ ‚îÄ‚îÄ‚ñ∫ Extraction des donn√©es brutes
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Prepa-Data    ‚îÇ ‚îÄ‚îÄ‚ñ∫ Data Mining & Feature Engineering
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                                  ‚îÇ
         ‚ñº                                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Student Profiler ‚îÇ              ‚îÇ Path Predictor   ‚îÇ
‚îÇ   (Clustering)   ‚îÇ              ‚îÇ   (XGBoost)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                                  ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ  Reco Builder    ‚îÇ
                ‚îÇ (Rule-Based ML)  ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 1Ô∏è‚É£ Data Mining - PrepaData Service

### üìç Localisation
**Service**: `services/prepa-data/`

### üîç Techniques utilis√©es

#### A. Extraction de donn√©es (ETL)
```python
# Extraction depuis le LMS
GET /lms-connector/students
GET /lms-connector/modules
GET /lms-connector/interactions
```

#### B. Feature Engineering
Le service transforme les donn√©es brutes en features exploitables :

**Features calcul√©es** :
- `average_score` : Score moyen de l'√©tudiant
- `average_participation` : Taux de participation (0-1)
- `total_time_spent` : Temps total pass√© (heures)
- `total_assignments` : Nombre de devoirs soumis
- `total_quiz_attempts` : Nombre de tentatives de quiz
- `risk_score` : Score de risque calcul√© (0-100)

**Formule du Risk Score** :
```python
risk_score = (
    (100 - average_score) * 0.4 +
    (1 - average_participation) * 100 * 0.3 +
    (max_time - total_time_spent) / max_time * 100 * 0.3
)
```

#### C. Agr√©gation et statistiques
- Calcul de moyennes par √©tudiant/module
- D√©tection d'anomalies dans les patterns d'apprentissage
- Cr√©ation de datasets pour l'entra√Ænement ML

### üìä Donn√©es stock√©es
- **Base de donn√©es** : PostgreSQL (`edupath_prepa`)
- **Format** : Tables normalis√©es avec index pour performance
- **Volume** : Donn√©es de tous les √©tudiants et interactions

---

## 2Ô∏è‚É£ Machine Learning - Path Predictor

### üìç Localisation
**Service**: `services/path-predictor/`

### ü§ñ Algorithme : XGBoost Classifier

#### Pourquoi XGBoost ?
- ‚úÖ Excellent pour la classification binaire
- ‚úÖ G√®re bien les donn√©es tabulaires
- ‚úÖ R√©sistant √† l'overfitting
- ‚úÖ Rapide en pr√©diction
- ‚úÖ Interpr√©table (feature importance)

### üéì Entra√Ænement du mod√®le

#### A. Pr√©paration des donn√©es
```python
# Features d'entr√©e (X)
feature_cols = [
    'average_score',           # Score moyen
    'average_participation',   # Participation
    'total_time_spent',        # Temps d'√©tude
    'total_assignments',       # Devoirs
    'total_quiz_attempts',     # Quiz
    'risk_score'              # Score de risque
]

# Label (y)
will_fail = 1 if failure_prob > 0.5 else 0
```

#### B. Hyperparam√®tres
```python
XGBClassifier(
    n_estimators=100,      # 100 arbres
    max_depth=5,           # Profondeur max
    learning_rate=0.1,     # Taux d'apprentissage
    random_state=42        # Reproductibilit√©
)
```

#### C. M√©triques de performance
- **Accuracy** : Pr√©cision globale du mod√®le
- **Precision/Recall** : Pour d√©tecter les √©tudiants √† risque
- **Feature Importance** : Quelles features influencent le plus

### üîÆ Pr√©diction

**Input** :
```json
{
  "student_id": 12345
}
```

**Output** :
```json
{
  "will_fail": false,
  "failure_probability": 0.23,
  "success_probability": 0.77,
  "risk_level": "Low"
}
```

**Niveaux de risque** :
- `High` : probability ‚â• 0.7
- `Medium` : 0.4 ‚â§ probability < 0.7
- `Low` : probability < 0.4

### üìà MLflow Integration
Tous les entra√Ænements sont track√©s avec MLflow :
- **M√©triques** : accuracy, n_samples
- **Param√®tres** : max_depth, learning_rate
- **Mod√®les** : Sauvegarde automatique
- **Run ID** : Tra√ßabilit√© compl√®te

---

## 3Ô∏è‚É£ Machine Learning - Student Profiler

### üìç Localisation
**Service**: `services/student-profiler/`

### ü§ñ Algorithmes utilis√©s

#### A. K-Means Clustering
**Objectif** : Regrouper les √©tudiants en profils similaires

```python
KMeans(
    n_clusters=3,      # 3 profils
    random_state=42,
    n_init=10
)
```

**Les 3 profils** :
1. **High Performer** : Score √©lev√©, risque faible
2. **Average Learner** : Performance moyenne
3. **At Risk** : Score faible, risque √©lev√©

#### B. PCA (Principal Component Analysis)
**Objectif** : R√©duction de dimensionnalit√©

```python
PCA(n_components=3)  # 6 features ‚Üí 3 composantes
```

**Avantages** :
- R√©duit le bruit dans les donn√©es
- Am√©liore la vitesse du clustering
- Visualisation possible en 3D

#### C. StandardScaler
**Objectif** : Normalisation des features

```python
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

**Pourquoi ?** Les features ont des √©chelles diff√©rentes (score 0-100, participation 0-1)

### üéØ Classification des profils

**Algorithme de mapping** :
```python
# Calcul d'un indicateur de performance
performance_indicator = average_score - (risk_score * 0.5)

# Tri des clusters par performance
cluster_mapping = {
    best_cluster: 0,    # High Performer
    mid_cluster: 1,     # Average Learner
    worst_cluster: 2    # At Risk
}
```

### üìä Output
```json
{
  "cluster": 0,
  "profile_name": "High Performer"
}
```

---

## 4Ô∏è‚É£ Syst√®me de Recommandation - Reco Builder

### üìç Localisation
**Service**: `services/reco-builder/`

### ü§ñ Approche : Rule-Based ML

#### A. Analyse des difficult√©s
```python
def get_student_difficulties(student_id):
    difficulties = []
    
    if average_score < 60:
        difficulties.append('low_performance')
    if average_participation < 0.7:
        difficulties.append('low_engagement')
    if risk_score > 50:
        difficulties.append('high_risk')
    if total_time_spent < 30:
        difficulties.append('low_study_time')
```

#### B. Scoring des ressources
**Algorithme de pertinence** :
```python
def score_resource(resource, difficulties):
    score = 0.0
    
    # R√®gle 1: Performance faible ‚Üí Ressources Beginner
    if 'low_performance' in difficulties:
        if difficulty_level == 'beginner':
            score += 3
    
    # R√®gle 2: Engagement faible ‚Üí Vid√©os/Exercices
    if 'low_engagement' in difficulties:
        if resource_type in ['video', 'exercise']:
            score += 3
    
    # R√®gle 3: Risque √©lev√© ‚Üí Ressources de r√©vision
    if 'high_risk' in difficulties:
        if 'revision' in tags:
            score += 2
    
    return score
```

#### C. Ranking et s√©lection
```python
# Tri par score d√©croissant
scored.sort(key=lambda r: r['relevance_score'], reverse=True)

# Top-K recommandations
recommendations = scored[:top_k]
```

### üìö Donn√©es de ressources
**Source** : `data/resources.csv`

**Colonnes** :
- `resource_id` : Identifiant unique
- `resource_name` : Nom de la ressource
- `resource_type` : Type (video, article, exercise, etc.)
- `module_id` : Module associ√©
- `difficulty_level` : Niveau (beginner, intermediate, advanced)
- `tags` : Tags s√©par√©s par virgules
- `description` : Description

---

## 5Ô∏è‚É£ Orchestration - Apache Airflow

### üìç Localisation
**Service**: `services/airflow/`

### üîÑ DAGs (Directed Acyclic Graphs)

#### Pipeline de donn√©es quotidien
```python
# Exemple de DAG
extract_data >> transform_data >> train_models >> update_predictions
```

**T√¢ches automatis√©es** :
1. **Extraction** : R√©cup√©ration des nouvelles donn√©es LMS
2. **Transformation** : Feature engineering
3. **Entra√Ænement** : Re-entra√Ænement des mod√®les ML
4. **Pr√©diction** : Mise √† jour des pr√©dictions
5. **Alertes** : Notification des √©tudiants √† risque

### ‚è∞ Scheduling
- **Fr√©quence** : Quotidienne (configurable)
- **Retry** : 3 tentatives en cas d'√©chec
- **Monitoring** : Interface web Airflow (port 8081)

---

## 6Ô∏è‚É£ Tracking & Versioning - MLflow

### üìç Localisation
**Service**: `services/mlflow/`

### üìä Fonctionnalit√©s

#### A. Experiment Tracking
```python
with mlflow.start_run():
    # Entra√Ænement
    model.fit(X, y)
    
    # Log des m√©triques
    mlflow.log_metric("accuracy", accuracy)
    mlflow.log_metric("f1_score", f1)
    
    # Log des param√®tres
    mlflow.log_param("max_depth", 5)
    mlflow.log_param("learning_rate", 0.1)
    
    # Sauvegarde du mod√®le
    mlflow.xgboost.log_model(model, "model")
```

#### B. Model Registry
- **Versioning** : Tous les mod√®les sont versionn√©s
- **Staging** : Mod√®les en test vs production
- **Rollback** : Retour √† une version pr√©c√©dente possible

#### C. Artifacts Storage
- **Mod√®les** : Fichiers .pkl, .json
- **M√©triques** : Historique complet
- **Visualisations** : Courbes, matrices de confusion

### üåê Interface Web
**URL** : `http://localhost:5000`

---

## 7Ô∏è‚É£ Benchmarking - Performance Monitoring

### üìç Localisation
**Service**: `services/benchmarks-service/`

### üìà M√©triques suivies

#### A. M√©triques ML
- **Accuracy** : Pr√©cision des pr√©dictions
- **Latency** : Temps de r√©ponse des mod√®les
- **Throughput** : Nombre de pr√©dictions/seconde

#### B. M√©triques Data
- **Data Quality** : Taux de donn√©es manquantes
- **Feature Distribution** : D√©tection de drift
- **Pipeline Health** : Statut des ETL

#### C. M√©triques Business
- **Student Engagement** : Taux d'utilisation
- **Recommendation CTR** : Taux de clic sur recommandations
- **Risk Alert Accuracy** : Pr√©cision des alertes

---

## üîß Technologies utilis√©es

### Machine Learning
| Technologie | Usage | Service |
|------------|-------|---------|
| **XGBoost** | Classification (pr√©diction d'√©chec) | path-predictor |
| **Scikit-learn** | Clustering, PCA, preprocessing | student-profiler |
| **Pandas** | Manipulation de donn√©es | Tous |
| **NumPy** | Calculs num√©riques | Tous |

### Deep Learning
| Technologie | Usage potentiel | Statut |
|------------|-----------------|--------|
| **Transformers** | NLP pour analyse de textes | Pr√©vu (reco-builder) |
| **FAISS** | Recherche vectorielle | Pr√©vu (reco-builder) |

### Data Engineering
| Technologie | Usage | Service |
|------------|-------|---------|
| **Apache Airflow** | Orchestration ETL | airflow |
| **PostgreSQL** | Stockage donn√©es | Tous |
| **MLflow** | ML Ops | mlflow |

---

## üìä Flux de donn√©es complet

```
1. EXTRACTION (LMS Connector)
   ‚Üì
2. DATA MINING (Prepa-Data)
   - Feature Engineering
   - Agr√©gation
   - Calcul du risk_score
   ‚Üì
3. MACHINE LEARNING
   ‚îú‚îÄ‚Üí Path Predictor (XGBoost)
   ‚îÇ   - Pr√©diction d'√©chec
   ‚îÇ   - Calcul de probabilit√©s
   ‚îÇ
   ‚îî‚îÄ‚Üí Student Profiler (K-Means + PCA)
       - Clustering en 3 profils
       - Classification des √©tudiants
   ‚Üì
4. RECOMMANDATION (Reco Builder)
   - Analyse des difficult√©s
   - Scoring des ressources
   - Top-K recommandations
   ‚Üì
5. DELIVERY (APIs)
   - Student Coach API
   - Teacher Console
   - Student Portal
```

---

## üéì Cas d'usage concrets

### Exemple 1 : D√©tection pr√©coce d'√©chec
```
√âtudiant ‚Üí Features ‚Üí XGBoost ‚Üí Probabilit√© 0.75 ‚Üí Alerte "High Risk"
```

### Exemple 2 : Recommandation personnalis√©e
```
√âtudiant ‚Üí Profil "At Risk" ‚Üí Ressources Beginner + Vid√©os ‚Üí Top 5
```

### Exemple 3 : Suivi de progression
```
√âtudiant ‚Üí Clustering ‚Üí "Average Learner" ‚Üí Tableau de bord adapt√©
```

---

## üöÄ Am√©liorations futures

### Court terme
- [ ] Ajout de features temporelles (tendances)
- [ ] Mod√®les par module (sp√©cialisation)
- [ ] A/B testing des recommandations

### Moyen terme
- [ ] Deep Learning pour NLP (analyse de feedbacks)
- [ ] Reinforcement Learning (optimisation de parcours)
- [ ] Explainability (SHAP values)

### Long terme
- [ ] Mod√®les multi-modaux (texte + comportement)
- [ ] Transfer Learning entre √©tablissements
- [ ] AutoML pour optimisation automatique

---

## üìö R√©f√©rences

### Documentation
- **XGBoost** : https://xgboost.readthedocs.io/
- **Scikit-learn** : https://scikit-learn.org/
- **MLflow** : https://mlflow.org/
- **Airflow** : https://airflow.apache.org/

### Papers
- Chen & Guestrin (2016) - XGBoost: A Scalable Tree Boosting System
- MacQueen (1967) - K-Means Clustering
- Pearson (1901) - Principal Component Analysis

---

## üë• Contact & Support

Pour toute question sur l'impl√©mentation ML/DL :
- **Documentation technique** : Voir `/docs` dans chaque service
- **Logs MLflow** : http://localhost:5000
- **Monitoring Airflow** : http://localhost:8081

---

**Version** : 1.0  
**Derni√®re mise √† jour** : D√©cembre 2025  
**Projet** : EduPath - Plateforme d'apprentissage adaptatif
